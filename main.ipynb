{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "#import os\n",
    "import emoji as emoji\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import AutoModel\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6452</td>\n",
       "      <td>@indigomermaidd You're the exception , you wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4884</td>\n",
       "      <td>If a woman doesn't want you just unleash your ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1931</td>\n",
       "      <td>Son of Jamestown, Protestants that made the US...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4942</td>\n",
       "      <td>Literally just got hit by a car bc this dumb b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4721</td>\n",
       "      <td>charli: fuck you bitch charli: omg why am i so...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  HS  TR  AG\n",
       "0  6452  @indigomermaidd You're the exception , you wer...   1   1   0\n",
       "1  4884  If a woman doesn't want you just unleash your ...   1   0   0\n",
       "2  1931  Son of Jamestown, Protestants that made the US...   0   0   0\n",
       "3  4942  Literally just got hit by a car bc this dumb b...   1   1   0\n",
       "4  4721  charli: fuck you bitch charli: omg why am i so...   1   1   0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "traindf = pd.read_csv('D:\\\\Sem 2\\\\NLP\\\\Project\\\\train.csv')\n",
    "print(traindf.shape[0])\n",
    "traindf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6452</td>\n",
       "      <td>@indigomermaidd You're the exception , you wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4884</td>\n",
       "      <td>If a woman doesn't want you just unleash your ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4942</td>\n",
       "      <td>Literally just got hit by a car bc this dumb b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4721</td>\n",
       "      <td>charli: fuck you bitch charli: omg why am i so...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5402</td>\n",
       "      <td>@GhostofGigi Are you calling me a Twitter Whor...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  HS  TR  AG\n",
       "0  6452  @indigomermaidd You're the exception , you wer...   1   1   0\n",
       "1  4884  If a woman doesn't want you just unleash your ...   1   0   0\n",
       "2  4942  Literally just got hit by a car bc this dumb b...   1   1   0\n",
       "3  4721  charli: fuck you bitch charli: omg why am i so...   1   1   0\n",
       "4  5402  @GhostofGigi Are you calling me a Twitter Whor...   1   1   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "traindf_2 = pd.read_csv('D:\\\\Sem 2\\\\NLP\\\\Project\\\\filtered_train.csv')\n",
    "print(traindf_2.shape[0])\n",
    "traindf_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class BERT_LSTM_Model(nn.Module):\n",
    "\n",
    "  def __init__(self, bert, n_class):\n",
    "    dropout_rate = 0.1\n",
    "    lstm_hidden_size = None\n",
    "\n",
    "    super(BERT_LSTM_Model, self).__init__()\n",
    "    self.bert = bert\n",
    "\n",
    "    if not lstm_hidden_size:\n",
    "      self.lstm_hidden_size = self.bert.config.hidden_size\n",
    "    else:\n",
    "      self.lstm_hidden_size = lstm_hidden_size\n",
    "    self.n_class = n_class\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.lstm = nn.LSTM(self.bert.config.hidden_size, self.lstm_hidden_size, bidirectional=True)\n",
    "    self.hidden_to_softmax = nn.Linear(self.lstm_hidden_size * 2, n_class, bias=True)\n",
    "    self.dropout = nn.Dropout(p=self.dropout_rate)\n",
    "    self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, sent_id, mask):\n",
    "    encoded_layers = self.bert(sent_id, attention_mask=mask, output_hidden_states=True)[2] #,output_all_encoded_layers=False)   #output_hidden_states output_hidden_states=True\n",
    "    bert_hidden_layer = encoded_layers[12]\n",
    "    bert_hidden_layer = bert_hidden_layer.permute(1, 0, 2)   #permute rotates the tensor. if tensor.shape = 3,4,5  tensor.permute(1,0,2), then tensor,shape= 4,3,5  (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "    sents_lengths = [36 for i in range(len(sent_id))]\n",
    "    enc_hiddens, (last_hidden, last_cell) = self.lstm(pack_padded_sequence(bert_hidden_layer, sents_lengths, enforce_sorted=False)) #enforce_sorted=False  #pack_padded_sequence(data and batch_sizes\n",
    "    output_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)  # (batch_size, 2*hidden_size)\n",
    "    output_hidden = self.dropout(output_hidden)\n",
    "    pre_softmax = self.hidden_to_softmax(output_hidden)\n",
    "\n",
    "    return self.softmax(pre_softmax)\n",
    "  \n",
    "\n",
    "# class BERT_LSTM_Model(nn.Module):\n",
    "#     def __init__(self, bert, n_class):\n",
    "#         super(BERT_LSTM_Model, self).__init__()\n",
    "#         self.bert = bert\n",
    "#         self.lstm = nn.LSTM(self.bert.config.hidden_size, self.bert.config.hidden_size, bidirectional=True)\n",
    "#         self.hidden_to_softmax = nn.Linear(self.bert.config.hidden_size * 2, n_class, bias=True)\n",
    "#         self.dropout = nn.Dropout(p=0.1)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, sent_id, mask):\n",
    "#         outputs = self.bert(sent_id, attention_mask=mask)\n",
    "#         bert_hidden_layer = outputs.last_hidden_state\n",
    "#         bert_hidden_layer = bert_hidden_layer.permute(1, 0, 2)\n",
    "#         enc_hiddens, (last_hidden, last_cell) = self.lstm(bert_hidden_layer)\n",
    "#         output_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)\n",
    "#         output_hidden = self.dropout(output_hidden)\n",
    "#         pre_softmax = self.hidden_to_softmax(output_hidden)\n",
    "#         return self.softmax(pre_softmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(ty):\n",
    "    \n",
    "    train_labels = traindf[ty]\n",
    "\n",
    "    return traindf['text'].tolist(), train_labels\n",
    "\n",
    "def read_dataset_2(ty):\n",
    "    \n",
    "    train_labels_2 = traindf_2[ty]\n",
    "\n",
    "    return traindf_2['text'].tolist(), train_labels_2\n",
    "\n",
    "\n",
    "def tokenize(tweet):\n",
    "    # instantiate the tokenizer class\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, \n",
    "                              strip_handles=True,\n",
    "                              reduce_len=True)\n",
    "\n",
    "    # tokenize the tweets\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens: # Go through every word in your tokens list\n",
    "        if word not in string.punctuation:  # remove punctuation\n",
    "            tweets_clean.append(word)\n",
    "    result = tweets_clean\n",
    "    return \" \".join(result)\n",
    "\n",
    "emoticons = [':-)', ':)', '(:', '(-:', ':))', '((:', ':-D', ':D', 'X-D', 'XD', 'xD', 'xD', '<3', '</3', ':\\*',\n",
    "                 ';-)',\n",
    "                 ';)', ';-D', ';D', '(;', '(-;', ':-(', ':(', '(:', '(-:', ':,(', ':\\'(', ':\"(', ':((', ':D', '=D',\n",
    "                 '=)',\n",
    "                 '(=', '=(', ')=', '=-O', 'O-=', ':o', 'o:', 'O:', 'O:', ':-o', 'o-:', ':P', ':p', ':S', ':s', ':@',\n",
    "                 ':>',\n",
    "                 ':<', '^_^', '^.^', '>.>', 'T_T', 'T-T', '-.-', '*.*', '~.~', ':*', ':-*', 'xP', 'XP', 'XP', 'Xp',\n",
    "                 ':-|',\n",
    "                 ':->', ':-<', '$_$', '8-)', ':-P', ':-p', '=P', '=p', ':*)', '*-*', 'B-)', 'O.o', 'X-(', ')-X']\n",
    "\n",
    "def preprocess(tweet):\n",
    "    result = tweet.replace('rt @','@')\n",
    "    result = result.replace('@','<user> @')\n",
    "    # it will remove hyperlinks\n",
    "    result = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '<url>', result)\n",
    "\n",
    "    # it will remove hashtags. We have to be careful here not to remove \n",
    "    # the whole hashtag because text of hashtags contains huge information. \n",
    "    # only removing the hash # sign from the word\n",
    "    result = re.sub(r'#', '<hashtag>', result)\n",
    "\n",
    "    # Replace multiple dots with space\n",
    "    result = re.sub('\\.\\.+', ' ', result) \n",
    "\n",
    "\n",
    "\n",
    "    for char in result:\n",
    "        if emoji.is_emoji(char):\n",
    "            result = result.replace(char, \"<emoticon >\")\n",
    "    for emo in emoticons:\n",
    "        result = result.replace(emo, \"<emoticon >\")\n",
    "\n",
    "    result = tokenize(result)\n",
    "    # it will remove single numeric terms in the tweet. \n",
    "    result = re.sub(r'[0-9]+', '<number>', result)\n",
    "    result = re.sub(r'<number>\\s?st', '<number>', result)\n",
    "    result = re.sub(r'<number>\\s?nd', '<number>', result)\n",
    "    result = re.sub(r'<number>\\s?rd', '<number>', result)\n",
    "    result = re.sub(r'<number>\\s?th', '<number>', result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def pre_process_dataset(values):\n",
    "    new_values = list()\n",
    "    for value in values:\n",
    "        new_values.append(preprocess(value.lower()))\n",
    "#     print(values[:5])\n",
    "#     print(new_values[:5])\n",
    "    return new_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, labels):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    for sentence in data:\n",
    "        bert_inp = bert_tokenizer.__call__(sentence, max_length=36,\n",
    "                                           padding='max_length', pad_to_max_length=True,\n",
    "                                           truncation=True, return_token_type_ids=False)\n",
    "\n",
    "        input_ids.append(bert_inp['input_ids'])\n",
    "        attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "    input_ids = np.asarray(input_ids)\n",
    "    attention_masks = np.array(attention_masks)\n",
    "    labels = np.array(labels)\n",
    "    return input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process(ty):\n",
    "\n",
    "    if (ty == 'HS'):\n",
    "        data, labels = read_dataset(ty)\n",
    "    else:\n",
    "        data, labels = read_dataset_2(ty)\n",
    "\n",
    "#     num_of_labels = len(labels.unique())\n",
    "    input_ids, attention_masks, labels = data_process(pre_process_dataset(data), labels)\n",
    "\n",
    "    return input_ids, attention_masks, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train(model,optimizer,train_dataloader,batch_size):\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    total = len(train_dataloader)\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "\n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = '█' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        labels_tensor = labels.clone().detach().to(device).long()\n",
    "        loss = cross_entropy(preds, labels_tensor)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss += float(loss.item())\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        total_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / (len(train_dataloader)*batch_size)\n",
    "\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    # returns the loss and predictions\n",
    "    return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate(model,val_dataloader,batch_size):\n",
    "    print(\"\\n\\nEvaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    total = len(val_dataloader)\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        \n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = '█' * filledLength + '>' * (filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "\n",
    "            labels_tensor = labels.clone().detach().to(device).long()\n",
    "            loss = cross_entropy(preds, labels_tensor)\n",
    "\n",
    "            total_loss += float(loss.item())\n",
    "            #preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            #total_preds.append(preds)\n",
    "            total_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / (len(val_dataloader)*batch_size)\n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the GPU\n",
    "# Setting up the device for GPU usage\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# loss function\n",
    "#cross_entropy = nn.NLLLoss(weight=weights)\n",
    "cross_entropy = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modelss(ty):\n",
    "\n",
    "    # Load Dataset\n",
    "    input_ids, attention_masks, labels = load_and_process(ty)\n",
    "    df = pd.DataFrame(list(zip(input_ids, attention_masks)), columns=['input_ids', 'attention_masks'])\n",
    "\n",
    "    # Class distribution\n",
    "    train_text, val_text, train_labels, val_labels = train_test_split(df, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train_count = len(train_labels)\n",
    "    val_count = len(val_labels)\n",
    "\n",
    "\n",
    "    # for train set\n",
    "    train_seq = torch.tensor(train_text['input_ids'].tolist())\n",
    "    train_mask = torch.tensor(train_text['attention_masks'].tolist())\n",
    "    train_y = torch.tensor(train_labels.astype(int))\n",
    "\n",
    "    # for validation set\n",
    "    val_seq = torch.tensor(val_text['input_ids'].tolist())\n",
    "    val_mask = torch.tensor(val_text['attention_masks'].tolist())\n",
    "    val_y = torch.tensor(val_labels.astype(int))\n",
    "\n",
    "\n",
    "\n",
    "    # define a batch size\n",
    "    batch_size = 32\n",
    "    learning_rate = 1e-5\n",
    "\n",
    "    # wrap tensors\n",
    "    train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "    # sampler for sampling the data during training\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    # dataLoader for train set\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    # wrap tensors\n",
    "    val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "    # sampler for sampling the data during training\n",
    "    val_sampler = SequentialSampler(val_data)\n",
    "    # dataLoader for validation set\n",
    "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    # import BERT-base pretrained model\n",
    "    bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "    # freeze all the parameters\n",
    "    for param in bert.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "    # pass the pre-trained BERT to our define architecture\n",
    "    model = BERT_LSTM_Model(bert, len(np.unique(labels)))\n",
    "    # push the model to GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    # define the optimizer\n",
    "    # optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "    # set initial loss to infinite\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "    epochs = 4\n",
    "    current = 1\n",
    "    # for each epoch\n",
    "    while current <= epochs:\n",
    "\n",
    "        print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "        # train model\n",
    "        train_loss, _ = train(model,optimizer,train_dataloader,batch_size)\n",
    "\n",
    "        # evaluate model\n",
    "        valid_loss, preds = evaluate(model,val_dataloader,batch_size)\n",
    "\n",
    "        # save the best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), f'model_{ty}.pth')\n",
    "\n",
    "\n",
    "        print(f'\\n\\nTraining Loss: {train_loss:.3f}')\n",
    "        print(f'Validation Loss: {valid_loss:.3f}')\n",
    "        \n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        print(classification_report(val_y, preds))\n",
    "\n",
    "        current = current + 1\n",
    "\n",
    "    # get predictions for test data\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelss('HS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelss('AG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelss('TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "testdf = pd.read_csv('D:\\\\Sem 2\\\\NLP\\\\Project\\\\test.csv')\n",
    "test_data = pre_process_dataset(testdf['text'].tolist())\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initialize an empty DataFrame to store predictions\n",
    "predictions_df = pd.DataFrame({'id': testdf['id']})\n",
    "\n",
    "# Define the labels\n",
    "labels = ['HS', 'TR', 'AG']\n",
    "\n",
    "# Iterate over each label\n",
    "for label in labels:\n",
    "    # Load the corresponding model\n",
    "    model_path = f'model_{label}.pth'\n",
    "    model = BERT_LSTM_Model(bert, 2)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Tokenize the test data\n",
    "    test_seq = torch.tensor([tokenizer.encode(i, max_length=36, pad_to_max_length=True) for i in test_data])\n",
    "    test_mask = torch.tensor([[float(i > 0) for i in ii] for ii in test_seq])\n",
    "    \n",
    "    # Get predictions for test data\n",
    "    with torch.no_grad():\n",
    "        preds = model(test_seq.to(device), test_mask.to(device))\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "    \n",
    "    # Get the predicted labels\n",
    "    predictions_df[label] = np.argmax(preds, axis=1)\n",
    "\n",
    "# Apply conditions to the predictions\n",
    "predictions_df['TR'] = predictions_df.apply(lambda row: row['TR'] if row['HS'] == 1 else 0, axis=1)\n",
    "predictions_df['AG'] = predictions_df.apply(lambda row: row['AG'] if row['HS'] == 1 else 0, axis=1)\n",
    "\n",
    "# Round the predictions to binary values (0 or 1)\n",
    "predictions_df = predictions_df.round().astype(int)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('prediction_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
